# Multi-Provider Intelligence Configuration
# This file defines all supported AI providers and their routing configuration

[default]
timeout_ms = 12000
scoring_weights = { latency = 0.4, cost = 0.3, reliability = 0.2, bandwidth = 0.1 }
chain_of_thought_suppression = { suppress_for = ["summary", "code"], force_for = ["reasoning"] }
cost_optimization = { max_budget_per_hour = 10.0, preferred_providers_under_budget = ["ollama", "openai"] }

[providers.openai]
name = "OpenAI"
endpoint = "https://api.openai.com/v1"
capabilities = ["chat", "reasoning", "code", "embedding", "image"]
models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]
api_key_env = "OPENAI_API_KEY"
priority_tier = 1
cost_score = 0.8
default_timeout_ms = 10000
bandwidth_score = 0.9
supports_cot = true
cot_suppression_prompt = "Answer directly without showing your reasoning."

[providers.anthropic]
name = "Anthropic"
endpoint = "https://api.anthropic.com"
capabilities = ["chat", "reasoning", "code"]
models = ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]
api_key_env = "ANTHROPIC_API_KEY"
priority_tier = 1
cost_score = 0.9
default_timeout_ms = 15000
bandwidth_score = 0.8
supports_cot = true
cot_suppression_prompt = "Be direct and concise."

[providers.google]
name = "Google Gemini"
endpoint = "https://generativelanguage.googleapis.com"
capabilities = ["chat", "reasoning", "code", "image"]
models = ["gemini-pro", "gemini-pro-vision"]
api_key_env = "GOOGLE_API_KEY"
priority_tier = 2
cost_score = 0.6
default_timeout_ms = 12000
bandwidth_score = 0.7
supports_cot = true
cot_suppression_prompt = "Provide direct answers without explanation."

[providers.deepseek]
name = "DeepSeek"
endpoint = "https://api.deepseek.com"
capabilities = ["chat", "reasoning", "code"]
models = ["deepseek-chat", "deepseek-coder"]
api_key_env = "DEEPSEEK_API_KEY"
priority_tier = 2
cost_score = 0.3
default_timeout_ms = 10000
bandwidth_score = 0.8
supports_cot = true
cot_suppression_prompt = "Answer concisely."

[providers.ollama]
name = "Ollama (Local)"
endpoint = "http://127.0.0.1:11434"
capabilities = ["chat", "reasoning", "code", "embedding"]
models = ["llama2", "codellama", "mistral"]
api_key_env = null
priority_tier = 0
cost_score = 0.0
default_timeout_ms = 30000
bandwidth_score = 0.5
supports_cot = false

[providers.groq]
name = "Groq"
endpoint = "https://api.groq.com/openai/v1"
capabilities = ["chat", "reasoning", "code"]
models = ["mixtral-8x7b", "llama2-70b"]
api_key_env = "GROQ_API_KEY"
priority_tier = 2
cost_score = 0.4
default_timeout_ms = 8000
bandwidth_score = 0.95
supports_cot = true
cot_suppression_prompt = "Be direct."

[providers.together]
name = "Together AI"
endpoint = "https://api.together.xyz"
capabilities = ["chat", "reasoning", "code", "image"]
models = ["llama-2-70b", "codellama-34b"]
api_key_env = "TOGETHER_API_KEY"
priority_tier = 3
cost_score = 0.5
default_timeout_ms = 10000
bandwidth_score = 0.8
supports_cot = true
cot_suppression_prompt = "Answer directly."

[providers.replicate]
name = "Replicate"
endpoint = "https://api.replicate.com"
capabilities = ["chat", "reasoning", "code", "image"]
models = ["llama-2-70b", "codellama-34b"]
api_key_env = "REPLICATE_API_KEY"
priority_tier = 3
cost_score = 0.6
default_timeout_ms = 20000
bandwidth_score = 0.7
supports_cot = true
cot_suppression_prompt = "Be concise."

[providers.huggingface]
name = "Hugging Face"
endpoint = "https://api-inference.huggingface.co"
capabilities = ["chat", "reasoning", "code"]
models = ["microsoft/DialoGPT-medium", "facebook/blenderbot-400M-distill"]
api_key_env = "HUGGINGFACE_API_KEY"
priority_tier = 4
cost_score = 0.2
default_timeout_ms = 15000
bandwidth_score = 0.6
supports_cot = false

[providers.cohere]
name = "Cohere"
endpoint = "https://api.cohere.ai"
capabilities = ["chat", "reasoning", "code", "embedding"]
models = ["command", "base"]
api_key_env = "COHERE_API_KEY"
priority_tier = 3
cost_score = 0.7
default_timeout_ms = 10000
bandwidth_score = 0.75
supports_cot = true
cot_suppression_prompt = "Answer directly."

[providers.ai21]
name = "AI21 Labs"
endpoint = "https://api.ai21.com"
capabilities = ["chat", "reasoning", "code"]
models = ["j2-ultra", "j2-mid"]
api_key_env = "AI21_API_KEY"
priority_tier = 4
cost_score = 0.8
default_timeout_ms = 12000
bandwidth_score = 0.7
supports_cot = true
cot_suppression_prompt = "Be direct."
